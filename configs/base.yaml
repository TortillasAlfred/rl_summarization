#####################
### MISCELLANEOUS ###
#####################
seed: 42 # Random seed
dev: False

##################
### MODEL ARGS ###
##################
model: "a2c" # One of ['lead3', 'banditsum', 'a2c']
items_per_epoch: 50000
train_batch_size: 1
test_batch_size: 1
hidden_dim: 200
decoder_dim: 100
n_repeats_per_sample: 16
learning_rate: 0.001
epsilon: 0.1
n_sents_per_summary: 3

####################
### DATASET ARGS ###
####################
dataset: "cnn_dailymail" # One of ['cnn_dailymail']
data_path: "./data/cnn_dailymail" # Argument to the Dataset object
embeddings: "glove.6B.100d"
embeddings_location: "./data/embeddings"
sets: ["train", "val", "test"] # List containing combination of ['train', 'val', 'test']. If present, 'train' must be first

###################
### REWARD ARGS ###
###################
reward: "rouge" # One of ['rouge']
rouge_jobs: -1

####################
### TRAINER ARGS ###
####################
trainer: "pl" # One of ['gradient_free', 'pl']
save_path: "."
gradient_clip_val: 1
gpus: 1
overfit_pct: 0.0
fast_dev_run: False
max_epochs: 1000
distributed_backend: "dp" # one of ['dp', 'ddp', 'ddp2']
use_amp: False
print_nan_grads: False
